Here is a **clean, focused README.md only for HPA / Autoscaling**
You can **directly copyâ€“paste this into GitHub** âœ…
(No extra topics, only autoscaling)

---

# ğŸ“ˆ Kubernetes Autoscaling (HPA) â€“ Complete Guide

This README explains **Horizontal Pod Autoscaler (HPA)** in Kubernetes with **clear concepts, commands, YAML structure, and real troubleshooting**, based on hands-on practice.

---

## ğŸ”¹ What is Autoscaling in Kubernetes?

Autoscaling means **automatically adjusting resources** based on load.

Kubernetes supports:

* **HPA** â†’ Scales number of pods
* **VPA** â†’ Scales CPU/Memory of pods
* **Cluster Autoscaler** â†’ Scales nodes

ğŸ‘‰ This README focuses on **HPA (most commonly used in production)**.

---

## ğŸ”¹ What is HPA (Horizontal Pod Autoscaler)?

**HPA automatically increases or decreases the number of pods** in a Deployment/StatefulSet based on metrics like:

* CPU usage
* Memory usage
* Custom metrics

### Example:

* Traffic increases â†’ pods scale from 2 â†’ 5
* Traffic decreases â†’ pods scale back to 2

---

## ğŸ”¹ Prerequisites for HPA

### 1ï¸âƒ£ Metrics Server (MANDATORY)

HPA **will not work** without Metrics Server.

Check:

```bash
kubectl top nodes
kubectl top pods
```

If not installed:

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Restart:

```bash
kubectl -n kube-system rollout restart deployment metrics-server
```

---

### 2ï¸âƒ£ Deployment with resource requests

HPA requires **CPU requests** in Deployment.

Example:

```yaml
resources:
  requests:
    cpu: "100m"
    memory: "128Mi"
```

---

## ğŸ”¹ HPA YAML (autoscaling/v2 â€“ Recommended)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: online-shop-hpa
  namespace: online-shop
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: online-shop-deployment

  minReplicas: 1
  maxReplicas: 5

  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### ğŸ”‘ Explanation

* **scaleTargetRef** â†’ which Deployment to scale
* **minReplicas** â†’ minimum pods
* **maxReplicas** â†’ maximum pods
* **averageUtilization** â†’ CPU % threshold

---

## ğŸ”¹ Apply & Verify HPA

```bash
kubectl apply -f hpa.yml
kubectl get hpa -n online-shop
kubectl describe hpa online-shop-hpa -n online-shop
```

Check pod scaling:

```bash
kubectl get pods -n online-shop
```

---

## ğŸ”¹ autoscaling/v1 (Fallback â€“ CPU only)

Use this if your cluster does **not support autoscaling/v2**.

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: online-shop-hpa
  namespace: online-shop
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: online-shop-deployment
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
```

---

## ğŸ”¹ Common Errors & Fixes

### âŒ `no matches for kind HorizontalPodAutoscaler`

âœ”ï¸ Kubernetes version does not support `autoscaling/v2`
ğŸ‘‰ Use `autoscaling/v1`

---

### âŒ `unknown field spec.scaleTargetRef.maxReplicas`

âœ”ï¸ Wrong YAML indentation
ğŸ‘‰ `minReplicas`, `maxReplicas`, `metrics` must be **outside** `scaleTargetRef`

---

### âŒ `metrics not available`

âœ”ï¸ Metrics Server not running
ğŸ‘‰ Restart metrics-server

---

### âŒ HPA not scaling

âœ”ï¸ CPU usage not crossing threshold
âœ”ï¸ Resource requests missing in Deployment

---

## ğŸ”¹ Load Testing (to Trigger HPA)

```bash
kubectl exec -it <pod-name> -- sh
```

Inside pod:

```sh
while true; do wget -q -O- http://localhost; done
```

Watch scaling:

```bash
watch kubectl get pods -n online-shop
```

---

## ğŸ”¹ HPA vs VPA (Quick Comparison)

| Feature        | HPA            | VPA         |
| -------------- | -------------- | ----------- |
| Scales         | Pods           | CPU/Memory  |
| Pod restart    | âŒ No           | âœ… Yes       |
| Production use | âœ… Very common  | âš ï¸ Careful  |
| Best for       | Web apps, APIs | Jenkins, DB |

ğŸ‘‰ **HPA is preferred in most production workloads**

---

## ğŸ”¹ Best Practices (Production)

* Always define **CPU requests**
* Use **HPA for stateless apps**
* Avoid HPA + VPA on CPU together
* Monitor scaling using:

  ```bash
  kubectl describe hpa
  ```

---

## ğŸ§  Interview-Ready Answer

> **HPA automatically scales pods based on metrics like CPU usage. It is preferred in production because it scales without restarting pods and ensures high availability.**

---

## âœ… Summary

This README covered:

* What HPA is
* How it works
* Metrics Server
* Correct YAML structure
* Common errors & fixes
* Production best practices

---
